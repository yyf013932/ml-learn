{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用TensorFlow完成简单的MINST手写识别模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "#引入内置的minst数据\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#自动下载和读取MNIST数据，如果存在则不下载只读取\n",
    "#这里的mnist是collections.namedtuple('Datasets', ['train', 'validation', 'test'])定义的，也就是其中有train、validation、test3个域\n",
    "#每个域均是tensorflow自定义的一个类，其中的属性有images(表示图像数据)、labels(对应的数字)、num_examples(样本数量)、\n",
    "#epochs_completed(迭代完成数量)，有函数next_batch，用于下一个指定size的数据batch\n",
    "#images、labels为ndarray类型\n",
    "#关于数据集的更多信息参见tensorflow.contrib.learn.python.learn.datasets.mnist及tensorflow.contrib.learn.python.learn.datasets.base模块\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义预测模型，Node表示不限大小，这里表示的是样本数量不限，因为image被flaten为一行，输入数据为 样本大小×图片像素 的一个2阶tensor\n",
    "X = tf.placeholder(tf.float32,shape=[None,28*28])\n",
    "y = tf.placeholder(tf.float32,shape=[None,10])\n",
    "W = tf.Variable(tf.zeros([28*28,10]))\n",
    "bias = tf.Variable(tf.zeros([10]))\n",
    "Y_ = tf.nn.softmax(tf.matmul(X,W)+bias)\n",
    "#定义预测的准确度\n",
    "correct_prediction = tf.equal(tf.argmax(y , 1) ,tf.argmax(Y_ , 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "def cal_accuracy( datas, labels):\n",
    "    return accuracy.eval({ X : datas , y : labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "loss = tf.reduce_mean( -tf.reduce_sum( y  *  tf.log(Y_) , axis=1))\n",
    "#使用梯度下降\n",
    "train_ = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#设置需要记录的值，这里记录每一次迭代的训练集合训练集的代价函数\n",
    "loss_summary=tf.summary.scalar(\"loss\" , loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9191\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init);\n",
    "    #这里我使用两个不同的writer来写入log文件，这是为了在运行tensorboard时，能在同一张图里面看到训练和测试的损失\n",
    "    train_writer = tf.summary.FileWriter( 'logs/MINIST/run1/train',sess.graph)\n",
    "    test_writer = tf.summary.FileWriter( 'logs/MINIST/run1/test',sess.graph)\n",
    "    for i in range(1000):\n",
    "        batch_x , batch_y = mnist.train.next_batch(100)\n",
    "        _ , lossS = sess.run([train_ , loss_summary] , {X : batch_x , y : batch_y})\n",
    "        train_writer.add_summary(lossS,i)\n",
    "        lossS = sess.run(loss_summary , { X :mnist.test.images , y: mnist.test.labels})\n",
    "        test_writer.add_summary(lossS,i)\n",
    "    train_writer.close()\n",
    "    test_writer.close()\n",
    "    #打印在测试集上的预测准确率\n",
    "    print(cal_accuracy(mnist.test.images,mnist.test.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用TensorBoard进行模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型在训练阶段，会使用交叉检验集对模型的超参数（hyper-parameters）进行评估与选择，tensorboard可以很好的展现不同模型之间的差异。\n",
    "\n",
    "在这里，我们的超参数就是梯度下降的学习率和batch的大小，所以我以这两个参数为例，展示模型的评估和使用tensorboard进行分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 0.05-100\n",
      "path=%s logs\\MINIST\\0.05-100\\test\n",
      "start 0.05-200\n",
      "path=%s logs\\MINIST\\0.05-200\\test\n",
      "start 0.05-400\n",
      "path=%s logs\\MINIST\\0.05-400\\test\n",
      "start 0.20-100\n",
      "path=%s logs\\MINIST\\0.20-100\\test\n",
      "start 0.20-200\n",
      "path=%s logs\\MINIST\\0.20-200\\test\n",
      "start 0.20-400\n",
      "path=%s logs\\MINIST\\0.20-400\\test\n",
      "start 0.50-100\n",
      "path=%s logs\\MINIST\\0.50-100\\test\n",
      "start 0.50-200\n",
      "path=%s logs\\MINIST\\0.50-200\\test\n",
      "start 0.50-400\n",
      "path=%s logs\\MINIST\\0.50-400\\test\n"
     ]
    }
   ],
   "source": [
    "#设定了3个learn_rate和batch_size\n",
    "learn_rate = [ 0.05 , 0.2 , 0.5 ]\n",
    "batch_size = [100 , 200 , 400]\n",
    "#使用tensorboard时设置logdir为此目录，可以看到所有的运行情况，此时选择需要比较图进行对应的比较则可以看到对比情况\n",
    "LOG_DIR = \"logs\\MINIST\"\n",
    "\n",
    "def eval_model(learn_rate,batch_size):\n",
    "    ##重置参数\n",
    "    W.assign(tf.zeros([28*28,10]))\n",
    "    bias.assign(tf.zeros([10]))\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        path = \"%.2f-%d\" % (learn_rate , batch_size)\n",
    "        testFilePath = os.path.join(LOG_DIR , path , \"test\")\n",
    "        trainFilePath = os.path.join(LOG_DIR,path,\"train\")\n",
    "        print(\"path=%s\",testFilePath)\n",
    "        train_writer = tf.summary.FileWriter(trainFilePath,sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(testFilePath,sess.graph)\n",
    "        train1 = tf.train.GradientDescentOptimizer(learn_rate).minimize(loss)\n",
    "        #为了减少训练时间，设定为200次迭代\n",
    "        for i in range(200):\n",
    "            batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "            _ , lossS = sess.run([train1 , loss_summary] , {X : batch_x , y : batch_y})\n",
    "            train_writer.add_summary(lossS,i)\n",
    "            lossS = sess.run(loss_summary , { X :mnist.test.images , y: mnist.test.labels})\n",
    "            test_writer.add_summary(lossS,i)\n",
    "        train_writer.close()\n",
    "        test_writer.close()\n",
    "\n",
    "for r in learn_rate:\n",
    "    for batch in batch_size:\n",
    "        print(\"start %.2f-%d\" %(r,batch))\n",
    "        eval_model(r,batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
