{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化可以参考[TensorBoard README](https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/tensorboard/README.md)以及[TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard)\n",
    "[TensorFlowSubmit](https://www.youtube.com/watch?v=eBbEDRsCmv4&index=5&list=PLOU2XLYxmsIKGc_NBoIhTn2Qhraji53cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化主要是通过启动tensorboard，来可视化计算的值，而将tensorflow的计算过程传递给tensorboard实际上需要summary操作，并将计算的结果存入磁盘里，tensorboard则通过读取这些信息来进行可视化\n",
    "\n",
    "一个简单的步骤为：\n",
    "1. 对需要生产summary的节点添加对应的summary操作，所有的summary操作参见[summary operation](https://www.tensorflow.org/api_guides/python/summary)\n",
    "2. 执行summary操作。因为summary操作可能不被其他节点依赖，所以需要显式执行，可以使用[tf.summary.merge_all](https://www.tensorflow.org/api_docs/python/tf/summary/merge_all)将所有的summary生成一个节点进行执行\n",
    "3. 执行完summary操作后会生成一个序列化对象，然后持久化保存此对象.[tf.summaryFileWriter](https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard 通过命令 `tensorboard --logdir=path/to/logs`启动，然后进入localhost:6006即可访问tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Save Graph & Summary Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建模型后，创建session，然后使用`tf.summary.FileWriter`即可可视化计算图\n",
    "\n",
    "    outFile = tf.summary.FileWriter( 'logdir',sess.graph)\n",
    "    \n",
    "为了使模型图更好可视化，tensorflow使用name和namescope来组织模型\n",
    "    \n",
    "    with tf.namescope('name'):\n",
    "        your model code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow目前支持几种不同的summary\n",
    "1. scalar:普通标量，之后用于linechar分析，如loss、accuracy等\n",
    "2. image\n",
    "3. audio\n",
    "4. histogram：直方图，通常用于记录权重、偏差等模型参数\n",
    "5. tensor：under development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Embedding Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting log/mnist_tutorial/data\\train-images-idx3-ubyte.gz\n",
      "Extracting log/mnist_tutorial/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting log/mnist_tutorial/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting log/mnist_tutorial/data\\t10k-labels-idx1-ubyte.gz\n",
      "Starting run for lr_1E-04,conv=2,fc=2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5cd2aa1fc436>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Starting run for %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mhparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# Actually run with the new settings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mmnist_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_two_fc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_two_conv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5cd2aa1fc436>\u001b[0m in \u001b[0;36mmnist_model\u001b[1;34m(learning_rate, use_two_conv, use_two_fc, hparam)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massignment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOGDIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model.ckpt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "\n",
    "LOGDIR = 'log/mnist_tutorial/'\n",
    "\n",
    "### MNIST EMBEDDINGS ###\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=LOGDIR + 'data', one_hot=True)\n",
    "\n",
    "\n",
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n",
    "\n",
    "def mnist_model(learning_rate, use_two_conv, use_two_fc, hparam):\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Setup placeholders, and reshape the data\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input', x_image, 3)\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "\n",
    "    if use_two_conv:\n",
    "        conv1 = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "        conv_out = conv_layer(conv1, 32, 64, \"conv2\")\n",
    "    else:\n",
    "        conv1 = conv_layer(x_image, 1, 64, \"conv\")\n",
    "        conv_out = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "    flattened = tf.reshape(conv_out, [-1, 7 * 7 * 64])\n",
    "\n",
    "\n",
    "    if use_two_fc:\n",
    "        fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, \"fc1\")\n",
    "        embedding_input = fc1\n",
    "        embedding_size = 1024\n",
    "        logits = fc_layer(fc1, 1024, 10, \"fc2\")\n",
    "    else:\n",
    "        embedding_input = flattened\n",
    "        embedding_size = 7*7*64\n",
    "        logits = fc_layer(flattened, 7*7*64, 10, \"fc\")\n",
    "\n",
    "    with tf.name_scope(\"xent\"):\n",
    "        xent = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y), name=\"xent\")\n",
    "        tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    summ = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "    embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"test_embedding\")\n",
    "    assignment = embedding.assign(embedding_input)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(LOGDIR + hparam)\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    embedding_config = config.embeddings.add()\n",
    "    embedding_config.tensor_name = embedding.name\n",
    "    embedding_config.sprite.image_path = LOGDIR + 'sprite_1024.png'\n",
    "    embedding_config.metadata_path = LOGDIR + 'labels_1024.tsv'\n",
    "  # Specify the width and height of a single thumbnail.\n",
    "    embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
    "    for i in range(2001):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        if i % 5 == 0:\n",
    "            [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: batch[0], y: batch[1]})\n",
    "            writer.add_summary(s, i)\n",
    "        if i % 500 == 0:\n",
    "            sess.run(assignment, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "            saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "        \n",
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv):\n",
    "    conv_param = \"conv=2\" if use_two_conv else \"conv=1\"\n",
    "    fc_param = \"fc=2\" if use_two_fc else \"fc=1\"\n",
    "    return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)\n",
    "\n",
    "\n",
    "# You can try adding some more learning rates\n",
    "for learning_rate in [1E-4]:\n",
    "    # Include \"False\" as a value to try different model architectures\n",
    "    for use_two_fc in [True]:\n",
    "        \n",
    "        for use_two_conv in [True]:\n",
    "            # Construct a hyperparameter string for each one (example: \"lr_1E-3,fc=2,conv=2)\n",
    "            hparam = make_hparam_string(learning_rate, use_two_fc, use_two_conv)\n",
    "            print('Starting run for %s' % hparam)\n",
    "            # Actually run with the new settings\n",
    "            mnist_model(learning_rate, use_two_fc, use_two_conv, hparam)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-kernel",
   "language": "python",
   "name": "tensorflow-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
