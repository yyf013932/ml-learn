{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# import data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test data\n",
    "testX = mnist.test.images\n",
    "testY = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#初始化权重\n",
    "def weight_variable(shape):\n",
    "    data = tf.truncated_normal(stddev=0.01,shape=shape)\n",
    "    return tf.Variable(data)\n",
    "\n",
    "#初始化偏置单元\n",
    "def bais_variable(shape):\n",
    "    data = tf.constant(0.01,shape=shape)\n",
    "    return tf.Variable(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#这里只使用1隐含层神经元\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "in_units=784\n",
    "out_units=200\n",
    "W1 = weight_variable([784,200])\n",
    "W2 = tf.Variable(tf.zeros([200,10]))\n",
    "b1 = bais_variable([200])\n",
    "b2 = tf.Variable(tf.zeros(10))\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "hidden_layer = tf.nn.relu(tf.matmul(x,W1)+b1)\n",
    "hidden_layer_drop=tf.nn.dropout(hidden_layer,keep_prob)\n",
    "\n",
    "model = tf.nn.softmax(tf.matmul(hidden_layer_drop,W2)+b2)\n",
    "\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(model),reduction_indices=[1]))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(model,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(loss)\n",
    "\n",
    "def show_accuracy(testX,testY,keep_prob):\n",
    "    print(\"accuracy=\",sess.run(accuracy,{x:testX,y:testY,keep_prob:keep_prob}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar('loss_0_1000_1000',loss)\n",
    "tf.summary.scalar('accuracy_0_1000_1000',accuracy)\n",
    "tf.summary.histogram('W1_0_1000_1000',W1)\n",
    "tf.summary.histogram('b1_0_1000_1000',b1)\n",
    "tf.summary.histogram('W2_0_1000_1000',W2)\n",
    "tf.summary.histogram('b2_0_1000_1000',b2)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps 0 cost:2.303 accuracy:0.252\n",
      "steps 10 cost:1.608 accuracy:0.336\n",
      "steps 20 cost:1.218 accuracy:0.688\n",
      "steps 30 cost:1.005 accuracy:0.707\n",
      "steps 40 cost:0.866 accuracy:0.793\n",
      "steps 50 cost:0.466 accuracy:0.891\n",
      "steps 60 cost:0.403 accuracy:0.896\n",
      "steps 70 cost:0.373 accuracy:0.890\n",
      "steps 80 cost:0.370 accuracy:0.907\n",
      "steps 90 cost:0.340 accuracy:0.910\n",
      "steps 100 cost:0.313 accuracy:0.923\n",
      "steps 110 cost:0.276 accuracy:0.928\n",
      "steps 120 cost:0.303 accuracy:0.929\n",
      "steps 130 cost:0.299 accuracy:0.932\n",
      "steps 140 cost:0.281 accuracy:0.937\n",
      "steps 150 cost:0.300 accuracy:0.938\n",
      "steps 160 cost:0.224 accuracy:0.939\n",
      "steps 170 cost:0.240 accuracy:0.938\n",
      "steps 180 cost:0.214 accuracy:0.940\n",
      "steps 190 cost:0.245 accuracy:0.944\n",
      "steps 200 cost:0.187 accuracy:0.944\n",
      "steps 210 cost:0.231 accuracy:0.948\n",
      "steps 220 cost:0.197 accuracy:0.949\n",
      "steps 230 cost:0.180 accuracy:0.949\n",
      "steps 240 cost:0.213 accuracy:0.950\n",
      "steps 250 cost:0.173 accuracy:0.952\n",
      "steps 260 cost:0.160 accuracy:0.953\n",
      "steps 270 cost:0.214 accuracy:0.952\n",
      "steps 280 cost:0.175 accuracy:0.954\n",
      "steps 290 cost:0.184 accuracy:0.953\n",
      "steps 300 cost:0.166 accuracy:0.955\n",
      "steps 310 cost:0.192 accuracy:0.955\n",
      "steps 320 cost:0.171 accuracy:0.958\n",
      "steps 330 cost:0.176 accuracy:0.958\n",
      "steps 340 cost:0.188 accuracy:0.960\n",
      "steps 350 cost:0.199 accuracy:0.959\n",
      "steps 360 cost:0.142 accuracy:0.958\n",
      "steps 370 cost:0.158 accuracy:0.958\n",
      "steps 380 cost:0.145 accuracy:0.961\n",
      "steps 390 cost:0.136 accuracy:0.961\n",
      "steps 400 cost:0.143 accuracy:0.962\n",
      "steps 410 cost:0.145 accuracy:0.962\n",
      "steps 420 cost:0.188 accuracy:0.962\n",
      "steps 430 cost:0.151 accuracy:0.963\n",
      "steps 440 cost:0.110 accuracy:0.964\n",
      "steps 450 cost:0.118 accuracy:0.964\n",
      "steps 460 cost:0.098 accuracy:0.964\n",
      "steps 470 cost:0.133 accuracy:0.965\n",
      "steps 480 cost:0.161 accuracy:0.966\n",
      "steps 490 cost:0.139 accuracy:0.964\n",
      "steps 500 cost:0.122 accuracy:0.966\n",
      "steps 510 cost:0.119 accuracy:0.966\n",
      "steps 520 cost:0.142 accuracy:0.967\n",
      "steps 530 cost:0.114 accuracy:0.965\n",
      "steps 540 cost:0.108 accuracy:0.967\n",
      "steps 550 cost:0.122 accuracy:0.965\n",
      "steps 560 cost:0.105 accuracy:0.966\n",
      "steps 570 cost:0.135 accuracy:0.966\n",
      "steps 580 cost:0.128 accuracy:0.967\n",
      "steps 590 cost:0.127 accuracy:0.968\n",
      "steps 600 cost:0.136 accuracy:0.970\n",
      "steps 610 cost:0.102 accuracy:0.969\n",
      "steps 620 cost:0.127 accuracy:0.968\n",
      "steps 630 cost:0.093 accuracy:0.970\n",
      "steps 640 cost:0.116 accuracy:0.969\n",
      "steps 650 cost:0.113 accuracy:0.969\n",
      "steps 660 cost:0.114 accuracy:0.969\n",
      "steps 670 cost:0.118 accuracy:0.971\n",
      "steps 680 cost:0.102 accuracy:0.970\n",
      "steps 690 cost:0.104 accuracy:0.971\n",
      "steps 700 cost:0.118 accuracy:0.971\n",
      "steps 710 cost:0.090 accuracy:0.971\n",
      "steps 720 cost:0.098 accuracy:0.971\n",
      "steps 730 cost:0.101 accuracy:0.972\n",
      "steps 740 cost:0.101 accuracy:0.971\n",
      "steps 750 cost:0.109 accuracy:0.971\n",
      "steps 760 cost:0.083 accuracy:0.970\n",
      "steps 770 cost:0.103 accuracy:0.972\n",
      "steps 780 cost:0.126 accuracy:0.972\n",
      "steps 790 cost:0.103 accuracy:0.973\n",
      "steps 800 cost:0.074 accuracy:0.973\n",
      "steps 810 cost:0.078 accuracy:0.973\n",
      "steps 820 cost:0.080 accuracy:0.974\n",
      "steps 830 cost:0.094 accuracy:0.973\n",
      "steps 840 cost:0.082 accuracy:0.974\n",
      "steps 850 cost:0.120 accuracy:0.973\n",
      "steps 860 cost:0.095 accuracy:0.972\n",
      "steps 870 cost:0.083 accuracy:0.974\n",
      "steps 880 cost:0.099 accuracy:0.973\n",
      "steps 890 cost:0.085 accuracy:0.974\n",
      "steps 900 cost:0.083 accuracy:0.974\n",
      "steps 910 cost:0.085 accuracy:0.974\n",
      "steps 920 cost:0.092 accuracy:0.974\n",
      "steps 930 cost:0.111 accuracy:0.975\n",
      "steps 940 cost:0.107 accuracy:0.973\n",
      "steps 950 cost:0.089 accuracy:0.975\n",
      "steps 960 cost:0.090 accuracy:0.974\n",
      "steps 970 cost:0.062 accuracy:0.975\n",
      "steps 980 cost:0.095 accuracy:0.975\n",
      "steps 990 cost:0.091 accuracy:0.976\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "train_data = mnist.train\n",
    "\n",
    "trainWriter = tf.summary.FileWriter( 'logs/MNIST_NN_DR/train',sess.graph)\n",
    "testWriter = tf.summary.FileWriter( 'logs/MNIST_NN_DR/test',sess.graph)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_x , batch_y = mnist.train.next_batch(1000)\n",
    "    c , _ ,summaried = sess.run([loss,train_step,merged] , feed_dict={x:batch_x,y:batch_y,keep_prob:0.75})\n",
    "    if i%10==0:\n",
    "        trainWriter.add_summary(summaried,i)\n",
    "        testSummary,ac = sess.run([merged,accuracy],feed_dict={x:testX,y:testY,keep_prob:1.0})\n",
    "        testWriter.add_summary(testSummary,i)\n",
    "        print(\"steps %d cost:%.3f accuracy:%.3f\" % (i,c,ac) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-kernel",
   "language": "python",
   "name": "tensorflow-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
